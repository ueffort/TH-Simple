#!/bin/bash
CURRENT_PATH=$(pwd);
ROOT_PATH=$(cd `dirname $0`/../; pwd);
cd $CURRENT_PATH;

. $ROOT_PATH/script/common.sh

#开始
#--combine:如果设定，自动将{script}-combine.pig脚本作为执行完后的合并脚本，用于对local和remote分别执行script后的数据合并脚本，如果type为both则会执行，否则不执行
#合并逻辑：执行script后，将存放在CUMBINE_PATH内的数据下载到本地并且存放到本地集群，将2个数据通过combine脚本进行合并，并且最终存放在本地集群
#有一个集群执行错误，则不会发起合并操作
#其余参数不变
#script:执行的脚本
function usage() {
	echo "usage: --combine (-v -param asdf -param asdf) script.pig"
}

if [ $? != 0 ] ; then usage >&2 ; exit 1 ; fi

function get_pig_script_name(){
	name=`basename $1 .pig`
	full=$2
	if [ -z $full ]
	then
		echo $name
	else
		echo `dirname $1`"/"$name
	fi
}

function combine(){
	echo "================>combine step<=============="
	re=0
	echo "get remote "
	while true
	do
		$ROOT_PATH/bin/hadoop-tools --remote fs -get "$COMBINE_REMOTE" "$REMOTE_TMP/$TMP_COMBINE_PATH"
		if [ $? -ne 0 ]
		then
			if [ $re -eq 0 ]
			then
				re=1
				continue
			else
				break
			fi
		else
			re=0
			break
		fi
	done
	if [ $re -ne 0 ]
	then
		echo "get remote fail"
		return $re
	fi

	echo "download remote "
	while true
	do
		$ROOT_PATH/bin/cluster-tools download "$REMOTE_TMP/$TMP_COMBINE_PATH" "$LOCAL_TMP/"
		if [ $? -ne 0 ]
		then
			if [ $re -eq 0 ]
			then
				re=1
				continue
			else
				break
			fi
		else
			re=0
			break
		fi
	done
	if [ $re -ne 0 ]
	then
		echo "download remote fail"
		return $re
	fi
	echo "put local "
	while true
	do
		$ROOT_PATH/bin/hadoop-tools --local fs -put "$LOCAL_TMP/$TMP_COMBINE_PATH" "$COMBINE_REMOTE"
		if [ $? -ne 0 ]
		then
			if [ $re -eq 0 ]
			then
				re=1
				continue
			else
				break
			fi
		else
			re=0
			break
		fi
	done
	if [ $re -ne 0 ]
	then
		echo "put local fail"
		return $re
	fi

	param=$1" -param COMBINE_LOCAL=$COMBINE_LOCAL -param COMBINE_REMOTE=$COMBINE_REMOTE"
	pig_play "$COMBINE_SCRIPT" "$param" "$LOCAL_MODE"
}

function clean_combine(){
	$ROOT_PATH/bin/cluster-tools --remote shell "rm -rf $REMOTE_TMP/$TMP_COMBINE_PATH" &
	$ROOT_PATH/bin/cluster-tools --local shell "rm -rf $LOCAL_TMP/$TMP_COMBINE_PATH" &
	$ROOT_PATH/bin/hadoop-tools --remote fs -rmr "$COMBINE_REMOTE" &
	$ROOT_PATH/bin/hadoop-tools --local fs -rmr "$COMBINE_REMOTE" &
	$ROOT_PATH/bin/hadoop-tools --local fs -rmr "$COMBINE_LOCAL" &
	wait
}

function pig_play(){
	script=$1
	p=$2
	host=$3
	back=$4
	if [ $host = $REMOTE_MODE ]
	then
		COMBINE_PATH=$COMBINE_REMOTE
	elif [ $host = $LOCAL_MODE ]
	then
		COMBINE_PATH=$COMBINE_LOCAL
	fi

	p=$p" -param STORAGE_PREFIX=\"'{STORAGE_PREFIX}'\" -param PROJECT_PATH={PROJECT_PATH} -param CLUSTER_TYPE=\"'{CLUSTER_TYPE}'\" -param COMBINE_PATH=$COMBINE_PATH"
	p="PARAM='"$p"' PROJECT_PATH={PROJECT_PATH} SCRIPT=$script "
	p=`replace_globals "$p" "$host"`

	echo ansible_play pig "$p" "$host" $back
	ansible_play pig "$p" "$host" $back
}

cluster_host=$CLUSTER_HOST

combine=
param=
export SCRIPT=
COMBINE_SCRIPT=

while [ -n "$*" ]
do
	case $1 in
		--combine|--COMBINE)
			combine=true
		shift ;;
		-*)
			param=$param""$1" "
			if [ ${2:0:1} != "-" ]
			then
				param=$param""$2" ";
				shift 2
			else
				shift
			fi
		;;
		*)
			export SCRIPT=$1;
			break
		shift ;;
    esac
done

export TMP_COMBINE_PATH="/"${USER}"_"${PROJECT}"_"${TIMESTAMP}_`get_pig_script_name $SCRIPT`
#不用存储在永久存储中，直接存储在集群的hdfs即可
export COMBINE_LOCAL=${LOCAL_HADOOP_TMP}"/"${TMP_COMBINE_PATH}_${LOCAL_MODE}
export COMBINE_REMOTE=${REMOTE_HADOOP_TMP}"/"${TMP_COMBINE_PATH}_${REMOTE_MODE}
if [ -z $SCRIPT ]
then
	usage
	exit 1
fi
if [ $cluster_host = $LOCAL_MODE -o $cluster_host = $BOTH_MODE ]
then
	pig_play $SCRIPT "$param" $LOCAL_MODE true
	out_local=$ANSIBLE_OUT
	if [ ! -z $ANSIBLE_VERBOSE ]
	then
		echo "local:=>>>>>>>>>>>>>>>>>>>>>>>>>$out_local"
	fi
fi
if [ $cluster_host = $REMOTE_MODE -o $cluster_host = $BOTH_MODE ]
then
	pig_play $SCRIPT "$param" $REMOTE_MODE true
	out_remote=$ANSIBLE_OUT
	if [ ! -z $ANSIBLE_VERBOSE ]
	then
		echo "remote:=>>>>>>>>>>>>>>>>>>>>>>>>$out_remote"
	fi
fi

wait
e=0
for i in $out_local $out_remote
do
	if [ -z $i ]
	then
		continue
	fi
	parse_ansible_return $i
	e=$[$e + $?]
done

if [ $e -gt 0 ]
then
	exit $e
fi

if [ ! -z "$combine" -a $cluster_host != $LOCAL_MODE -a $cluster_host != $REMOTE_MODE ]
then
	if [ -z $COMBINE_SCRIPT ]
	then
		# 自动绑定合并的pig脚本
		COMBINE_SCRIPT=`get_pig_script_name $SCRIPT 1`"-combine.pig"
	fi
	combine "$param"
	re=$?
	clean_combine
	if [ $re -ne 0 ]
	then
		exit $re
	fi
	parse_ansible_return $ANSIBLE_OUT
	exit $?
fi
exit
